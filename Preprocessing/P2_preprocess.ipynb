{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa20c1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaned Successfully!\n",
      "New Shape: (40543, 24)\n",
      "   founder_age founder_gender  years_with_startup founder_role  \\\n",
      "1           59         Female                   4        Media   \n",
      "3           36         Female                   7    Education   \n",
      "5           38         Female                   3   Technology   \n",
      "6           47           Male                  23    Education   \n",
      "7           48           Male                  16      Finance   \n",
      "\n",
      "   monthly_revenue_generated work_life_balance_rating venture_satisfaction  \\\n",
      "1                     5534.0                     Poor                 High   \n",
      "3                     3989.0                     Good                 High   \n",
      "5                     9977.0                     Fair                 High   \n",
      "6                     3681.0                  Unknown              Unknown   \n",
      "7                    11223.0                Excellent            Very High   \n",
      "\n",
      "  startup_performance_rating  funding_rounds_led working_overtime  ...  \\\n",
      "1                        Low                   3               No  ...   \n",
      "3                       High                   1               No  ...   \n",
      "5              Below Average                   3               No  ...   \n",
      "6                       High                   1              Yes  ...   \n",
      "7                       High                   2               No  ...   \n",
      "\n",
      "   startup_stage team_size_category years_since_founding  remote_operations  \\\n",
      "1            Mid             Medium                 21.0                 No   \n",
      "3            Mid              Small                 50.0                Yes   \n",
      "5            Mid             Medium                 47.0                 No   \n",
      "6          Entry              Small                 93.0                 No   \n",
      "7          Entry             Medium                 88.0                 No   \n",
      "\n",
      "  leadership_scope innovation_support  startup_reputation founder_visibility  \\\n",
      "1               No                 No                Fair                Low   \n",
      "3               No                 No                Good             Medium   \n",
      "5               No                Yes                Fair               High   \n",
      "6               No                 No                Good             Medium   \n",
      "7               No                 No           Excellent                Low   \n",
      "\n",
      "  start_age target  \n",
      "1        55      0  \n",
      "3        29      0  \n",
      "5        35      1  \n",
      "6        24      1  \n",
      "7        32      0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data (assuming you are in the same session)\n",
    "# df = pd.read_csv('data/train.csv') # Uncomment if you need to reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "def clean_data(df):\n",
    "    # 1. Drop Duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # 2. Anomaly Removal\n",
    "    # Keep only founders 18 or older\n",
    "    df = df[df['founder_age'] >= 18]\n",
    "    \n",
    "    # Keep only valid tenures (started at age 16+)\n",
    "    df = df[(df['founder_age'] - df['years_with_startup']) >= 16]\n",
    "    \n",
    "    # 3. Missing Value Imputation\n",
    "    # Numerical: Median (robust to outliers)\n",
    "    num_cols = ['monthly_revenue_generated', 'years_since_founding', 'num_dependents']\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "    # Categorical: Treat \"Missing\" as \"Unknown\" for psychological surveys\n",
    "    # This captures the \"silence\" signal\n",
    "    df['work_life_balance_rating'] = df['work_life_balance_rating'].fillna('Unknown')\n",
    "    df['venture_satisfaction'] = df['venture_satisfaction'].fillna('Unknown')\n",
    "    \n",
    "    # For other structural columns, use Mode\n",
    "    df['team_size_category'] = df['team_size_category'].fillna(df['team_size_category'].mode()[0])\n",
    "    \n",
    "    # 4. Feature Engineering (Simplification)\n",
    "    # Create a \"Start Age\" feature to capture the age they started\n",
    "    df['start_age'] = df['founder_age'] - df['years_with_startup']\n",
    "    \n",
    "    # 5. Encoding Target\n",
    "    # Stayed -> 0, Left -> 1 (Standard for Churn/Exit prediction)\n",
    "    target_map = {'Stayed': 0, 'Left': 1}\n",
    "    df['target'] = df['retention_status'].map(target_map)\n",
    "    \n",
    "    # Drop unused columns\n",
    "    cols_to_drop = ['founder_id', 'retention_status']\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the cleaning\n",
    "df_clean = clean_data(df)\n",
    "\n",
    "print(\"Data Cleaned Successfully!\")\n",
    "print(f\"New Shape: {df_clean.shape}\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e917de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transformation Complete!\n",
      "Training Features Shape: (32434, 31)\n",
      "Testing Features Shape: (8109, 31)\n",
      "\n",
      "First 5 rows of processed data (All Numbers Now!):\n",
      "   founder_age  years_with_startup  monthly_revenue_generated  \\\n",
      "0     1.136680            1.229897                  -1.294496   \n",
      "1    -0.727069           -1.239229                   1.443614   \n",
      "2     0.870430           -1.136349                  -0.693043   \n",
      "3     1.314180            0.921256                  -0.074537   \n",
      "4     1.580430            0.303975                  -2.125930   \n",
      "\n",
      "   work_life_balance_rating  venture_satisfaction  startup_performance_rating  \\\n",
      "0                 -1.683026             -2.061083                    0.067999   \n",
      "1                  1.253636              1.091734                    0.067999   \n",
      "2                 -1.095694             -0.169393                    1.421057   \n",
      "3                 -1.095694             -1.430520                   -2.638117   \n",
      "4                 -1.683026             -2.061083                   -1.285059   \n",
      "\n",
      "   funding_rounds_led  working_overtime  distance_from_investor_hub  \\\n",
      "0           -0.834327         -0.695398                   -1.367234   \n",
      "1           -0.834327         -0.695398                    0.423160   \n",
      "2            1.182709         -0.695398                    0.036997   \n",
      "3            2.191228          1.438025                   -0.278955   \n",
      "4            1.182709         -0.695398                   -1.402340   \n",
      "\n",
      "   num_dependents  ...  founder_role_Media  founder_role_Technology  \\\n",
      "0       -0.393009  ...           -0.439264                -0.591522   \n",
      "1        0.274435  ...           -0.439264                 1.690555   \n",
      "2       -0.393009  ...            2.276536                -0.591522   \n",
      "3        1.609324  ...            2.276536                -0.591522   \n",
      "4       -0.393009  ...           -0.439264                -0.591522   \n",
      "\n",
      "   education_background_Bachelor’s Degree  education_background_High School  \\\n",
      "0                               -0.658010                         -0.494077   \n",
      "1                                1.519734                         -0.494077   \n",
      "2                               -0.658010                          2.023976   \n",
      "3                               -0.658010                         -0.494077   \n",
      "4                                1.519734                         -0.494077   \n",
      "\n",
      "   education_background_Master’s Degree  education_background_PhD  \\\n",
      "0                             -0.501021                 -0.232916   \n",
      "1                             -0.501021                 -0.232916   \n",
      "2                             -0.501021                 -0.232916   \n",
      "3                             -0.501021                 -0.232916   \n",
      "4                             -0.501021                 -0.232916   \n",
      "\n",
      "   personal_status_Married  personal_status_Single  team_size_category_Medium  \\\n",
      "0                -0.999507                1.356321                   0.949242   \n",
      "1                -0.999507               -0.737288                   0.949242   \n",
      "2                 1.000493               -0.737288                   0.949242   \n",
      "3                 1.000493               -0.737288                   0.949242   \n",
      "4                -0.999507                1.356321                   0.949242   \n",
      "\n",
      "   team_size_category_Small  \n",
      "0                 -0.630122  \n",
      "1                 -0.630122  \n",
      "2                 -0.630122  \n",
      "3                 -0.630122  \n",
      "4                 -0.630122  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def encode_and_split(df):\n",
    "    # --- 1. ORDINAL ENCODING (Preserving Order) ---\n",
    "    # We manually map these so the model knows 'Excellent' is better than 'Poor'\n",
    "    \n",
    "    rating_map = {'Unknown': 0, 'Low': 1, 'Poor': 1, 'Below Average': 2, \n",
    "                  'Fair': 3, 'Medium': 3, 'Average': 3, \n",
    "                  'Good': 4, 'High': 4, 'Very High': 5, 'Excellent': 5}\n",
    "    \n",
    "    # Apply to all rating-like columns\n",
    "    ord_cols = ['work_life_balance_rating', 'venture_satisfaction', \n",
    "                'startup_performance_rating', 'startup_reputation', 'founder_visibility']\n",
    "    \n",
    "    for col in ord_cols:\n",
    "        # Map and fill any unexpected values with 0 (Unknown)\n",
    "        df[col] = df[col].map(rating_map).fillna(0)\n",
    "\n",
    "    # Map Binary Columns (Yes/No)\n",
    "    binary_map = {'No': 0, 'Yes': 1}\n",
    "    bin_cols = ['working_overtime', 'remote_operations', 'innovation_support', 'leadership_scope']\n",
    "    for col in bin_cols:\n",
    "        df[col] = df[col].map(binary_map)\n",
    "\n",
    "    # Map Startup Stage (Roughly ordered)\n",
    "    stage_map = {'Entry': 1, 'Mid': 2, 'Senior': 3, 'Growth': 3, 'Established': 4}\n",
    "    df['startup_stage'] = df['startup_stage'].map(stage_map).fillna(1)\n",
    "\n",
    "    # --- 2. ONE-HOT ENCODING (Nominal Data) ---\n",
    "    # For Gender, Role, Education, etc.\n",
    "    # drop_first=True helps avoid multicollinearity (redundancy)\n",
    "    df = pd.get_dummies(df, columns=['founder_gender', 'founder_role', \n",
    "                                     'education_background', 'personal_status', \n",
    "                                     'team_size_category'], drop_first=True)\n",
    "\n",
    "    # --- 3. SPLITTING ---\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "    \n",
    "    # 80% Train, 20% Test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # --- 4. SCALING ---\n",
    "    # Scale numerical features so age (e.g., 40) doesn't get overpowered by revenue (e.g., 5000)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert back to dataframe for readability (optional but helpful)\n",
    "    X_train_final = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "    X_test_final = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "    \n",
    "    return X_train_final, X_test_final, y_train, y_test\n",
    "\n",
    "# Execute\n",
    "X_train, X_test, y_train, y_test = encode_and_split(df_clean)\n",
    "\n",
    "print(\"Data Transformation Complete!\")\n",
    "print(f\"Training Features Shape: {X_train.shape}\")\n",
    "print(f\"Testing Features Shape: {X_test.shape}\")\n",
    "print(\"\\nFirst 5 rows of processed data (All Numbers Now!):\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f39b9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [40543, 32434]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 8. Train final model on full training data\u001b[39;00m\n\u001b[32m     42\u001b[39m final_model = RandomForestClassifier(\n\u001b[32m     43\u001b[39m     n_estimators=\u001b[32m200\u001b[39m,\n\u001b[32m     44\u001b[39m     max_depth=\u001b[32m10\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     48\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m final_model.fit(X_scaled, y_train)\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# 9. Predict on processed test\u001b[39;00m\n\u001b[32m     53\u001b[39m predictions = final_model.predict(X_test_submit_scaled)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/MlLab/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/MlLab/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:359\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m X, y = validate_data(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    361\u001b[39m     X,\n\u001b[32m    362\u001b[39m     y,\n\u001b[32m    363\u001b[39m     multi_output=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    364\u001b[39m     accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    365\u001b[39m     dtype=DTYPE,\n\u001b[32m    366\u001b[39m     ensure_all_finite=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    367\u001b[39m )\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    372\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/MlLab/lib/python3.11/site-packages/sklearn/utils/validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/MlLab/lib/python3.11/site-packages/sklearn/utils/validation.py:1387\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1368\u001b[39m X = check_array(\n\u001b[32m   1369\u001b[39m     X,\n\u001b[32m   1370\u001b[39m     accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1382\u001b[39m     input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1383\u001b[39m )\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m check_consistent_length(X, y)\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/MlLab/lib/python3.11/site-packages/sklearn/utils/validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [40543, 32434]"
     ]
    }
   ],
   "source": [
    "# --- FINAL SUBMISSION PIPELINE ---\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Import preprocessing functions from earlier cells\n",
    "\n",
    "\n",
    "# 2. Load train & test\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# 3. Apply EXACT same cleaning to train\n",
    "train_clean = clean_data(train)\n",
    "\n",
    "# 4. Encode & scale using the SAME pipeline\n",
    "X_train, X_test_dummy, y_train, y_test_dummy = encode_and_split(train_clean)\n",
    "\n",
    "# 5. Prepare TEST data (must go through SAME cleaning)\n",
    "test['retention_status'] = 'Stayed'   # dummy—needed for clean_data\n",
    "test_clean = clean_data(test)\n",
    "\n",
    "# Drop target column we artificially added\n",
    "test_clean = test_clean.drop(columns=['target'])\n",
    "\n",
    "# 6. Apply ONE-HOT + ORDINAL encoding matching train\n",
    "# We need to align columns manually:\n",
    "test_encoded = pd.get_dummies(test_clean)\n",
    "train_encoded = pd.get_dummies(train_clean.drop(columns=['target']))\n",
    "\n",
    "# Align column sets\n",
    "test_encoded = test_encoded.reindex(columns=train_encoded.columns, fill_value=0)\n",
    "\n",
    "# 7. Scale test data using *TRAIN SCALER*\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(train_encoded)\n",
    "X_test_submit_scaled = scaler.transform(test_encoded)\n",
    "\n",
    "# 8. Train final model on full training data\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X_scaled, y_train)\n",
    "\n",
    "# 9. Predict on processed test\n",
    "predictions = final_model.predict(X_test_submit_scaled)\n",
    "\n",
    "# 10. Map back to labels\n",
    "inverse_map = {0: 'Stayed', 1: 'Left'}\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'founder_id': test['founder_id'],\n",
    "    'retention_status': [inverse_map[p] for p in predictions]\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Success! submission.csv created:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MlLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
